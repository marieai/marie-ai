import copy
import json
from collections import defaultdict
from datetime import datetime, timezone
from typing import Tuple

from marie.constants import (
    __default_extract_dir__,
)
from marie.executor.extract.util import layout_config
from marie.logging_core.predefined import default_logger as logger
from marie.query_planner.base import (
    NoopQueryDefinition,
    Query,
    QueryDefinition,
    QueryPlan,
)
from marie.query_planner.mapper import JobMetadata, has_mapper_config
from marie.query_planner.planner import (
    PlannerInfo,
    compute_job_levels,
    plan_to_yaml,
    query_planner,
    topological_sort,
)
from marie.scheduler.fixtures import *
from marie.scheduler.memory_frontier import MemoryFrontier
from marie.scheduler.models import WorkInfo

_mapper_warnings_shown = set()


def get_node_from_dag(work_id: str, dag: QueryPlan) -> Query:
    """
    Retrieves a node from the DAG by its ID.

    Args:
        work_id: The ID of the node to retrieve
        dag: The DAG to search in

    Returns:
        The node if found, None otherwise
    """
    for node in dag.nodes:
        if node.task_id == work_id:
            return node
    raise ValueError(f"Node with ID {work_id} not found in DAG")


def _is_noop_query_definition(node: QueryDefinition) -> bool:
    """
    Checks if the given node is a NoopQueryDefinition node.
    NoopQueryDefinition is a special type of node that does not perform any operation and are used for
    aggregation or as placeholders in the query plan.
    """
    try:
        return isinstance(node.definition, NoopQueryDefinition)
    except ImportError:
        # If import fails, try to check by class name
        return node.__class__.__name__ == "NoopQueryDefinition" or (
            hasattr(node, 'definition')
            and node.query_definition.__class__.__name__ == "NoopQueryDefinition"
        )


def _is_branch_query_definition(node: Query) -> bool:
    """
    Checks if the given node is a BRANCH or SWITCH query definition.
    These are control flow nodes that evaluate conditions and route execution.
    """
    from marie.query_planner.branching import (
        BranchQueryDefinition,
        PythonBranchQueryDefinition,
        SwitchQueryDefinition,
    )

    try:
        return isinstance(
            node.definition,
            (BranchQueryDefinition, SwitchQueryDefinition, PythonBranchQueryDefinition),
        )
    except ImportError:
        # Fallback to class name check
        class_name = node.definition.__class__.__name__
        return class_name in (
            "BranchQueryDefinition",
            "SwitchQueryDefinition",
            "PythonBranchQueryDefinition",
        )


def query_plan_work_items(work_info: WorkInfo) -> tuple[QueryPlan, list[WorkInfo]]:
    """
    Generates a query plan and associated work items by processing the provided
    work information object. The method builds a directed acyclic graph (DAG) of
    work items and computes hierarchical job levels for its tasks.

    :param work_info: An object encapsulating details about the work items,
                      including metadata and configuration needed to plan the
                      execution.

    :return: A tuple consisting of:
             - A `QueryPlan` object representing the plan generated by the
               query planner.
             - A list of `WorkInfo` objects, each representing an individual
               task/node in the execution plan's DAG.
    """
    # from metadata or fallback to name They can be this same
    query_planner_name = work_info.data.get("metadata", {}).get(
        "planner", work_info.name
    )

    planner_info = PlannerInfo(name=query_planner_name, base_id=work_info.id)
    plan = query_planner(planner_info)
    # pprint(plan.model_dump())
    # visualize_query_plan_graph(plan)
    yml_str = plan_to_yaml(plan)

    sorted_nodes = topological_sort(plan)
    job_levels = compute_job_levels(sorted_nodes, plan)
    # print("Topologically sorted nodes:", sorted_nodes)
    # print_sorted_nodes(sorted_nodes, plan)

    dag_nodes = []
    node_dict = {node.task_id: node for node in plan.nodes}

    for i, task_id in enumerate(sorted_nodes):
        node = node_dict.get(task_id)
        wi = copy.deepcopy(work_info)
        wi.id = node.task_id
        wi.job_level = job_levels[task_id]

        # Always use mapper config - will fall back to base config if layout-specific doesn't exist
        meta = JobMetadata.from_task(node, query_planner_name)
        meta_dict = meta.model_dump()  # need plain dict
        metadata = meta_dict["metadata"]
        wi.data['metadata'].update(metadata)

        # Log info about mapper config usage (only once per planner)
        if query_planner_name not in _mapper_warnings_shown:
            if has_mapper_config(__default_extract_dir__, query_planner_name):
                logger.debug(
                    f"Using layout-specific mapper configuration for {query_planner_name}"
                )
            else:
                logger.info(
                    f"No layout-specific mapper configuration found for {query_planner_name}, "
                    "using base mapper configuration."
                )
            _mapper_warnings_shown.add(query_planner_name)

        if i == 0:
            # this should already been handled by the query planner
            if node.dependencies:
                raise ValueError(
                    f"Root node has dependencies: {node.dependencies}, expected none"
                )
            work_info.dependencies = []  # Root node has no dependencies
            wi.dependencies = []
        else:
            wi.dependencies = node.dependencies
        dag_nodes.append(wi)

    return plan, dag_nodes


async def debug_candidates_and_plan(
    candidates_wi: list[WorkInfo],
    planned: list[Tuple[str, WorkInfo]],
    pick_slots: dict[str, int],
    active_dags: dict[str, QueryPlan],
    frontier: MemoryFrontier,
) -> None:
    """
    Debugs and writes candidates and planned jobs to a file if the
    environment variable `MARIE_DEBUG_QUERY_PLAN` is set.

    :param candidates_wi: A list of work info objects that are candidates for planning.
    :param planned: A list of tuples containing entrypoint and work info for planned jobs.
    :param pick_slots: The slots available for planning.
    :param active_dags: A dictionary of active DAGs with their IDs as keys.
    :param frontier: The memory frontier containing job states and information.
    """

    if "MARIE_DEBUG_QUERY_PLAN" not in os.environ:
        pass
        # return

    os.makedirs("/tmp/marie/plans", exist_ok=True)
    # timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S_%f")

    debug_file_path = f"/tmp/marie/plans/candidates_plan_debug_{timestamp}.txt"

    def _get_executor_from_work_info(work_info: Optional[WorkInfo]) -> str:
        """Extracts the executor name from a WorkInfo object."""
        if not work_info or not work_info.data:
            return "UNKNOWN"
        endpoint = work_info.data.get("metadata", {}).get("on", "")
        if not endpoint:
            return "UNKNOWN"
        if "://" in endpoint:
            return endpoint.split("://", 1)[0]
        return endpoint

    try:
        with open(debug_file_path, 'w') as debug_file:
            # debug_file.write("Nodes:\n")
            # debug_file.write(json.dumps(ClusterState.deployments, indent=4))

            debug_file.write("\n\n")
            debug_file.write("Slots:\n")
            debug_file.write(json.dumps(pick_slots, indent=4))
            debug_file.write("\n\n")

            debug_file.write("Memory Frontier State:\n")
            frontier_summary = frontier.summary(detail=True)
            debug_file.write(json.dumps(frontier_summary, indent=4))
            debug_file.write("\n\n")

            debug_file.write("Candidate Work Items:\n")
            for work_info in candidates_wi:
                debug_file.write(
                    f"Work ID: {work_info.id}, "
                    f"Priority: {work_info.priority}, "
                    f"Job Level: {work_info.job_level}, "
                    f"DAG ID: {work_info.dag_id}\n"
                )

            debug_file.write("\n\n")
            debug_file.write("Planned Jobs:\n")
            for entrypoint, work_info in planned:
                debug_file.write(
                    f"Entrypoint: {entrypoint}, "
                    f"Work ID: {work_info.id}, "
                    f"Priority: {work_info.priority}, "
                    f"Job Level: {work_info.job_level}, "
                    f"DAG ID: {work_info.dag_id}\n"
                )
            debug_file.write("\n\n")

            debug_file.write("Active DAG Completion States:\n")
            active_dag_ids = sorted(list(active_dags.keys()))

            for dag_id in active_dag_ids:
                dag_plan = active_dags.get(dag_id)
                if not dag_plan:
                    debug_file.write(
                        f"  DAG ID: {dag_id} - Plan not found in active_dags\n\n"
                    )
                    continue

                try:
                    sorted_node_ids = topological_sort(dag_plan)
                    node_map = {node.task_id: node for node in dag_plan.nodes}

                    total_nodes = len(sorted_node_ids)
                    completed_nodes = 0

                    debug_file.write(f"  DAG ID: {dag_id}\n")

                    # Batch fetch all job info for the DAG for efficiency
                    # job_infos = await asyncio.gather(
                    #     *[self.get_job(node_id) for node_id in sorted_node_ids]
                    # )
                    # job_info_map = {ji.id: ji for ji in job_infos if ji}
                    job_info_map = {
                        j.id: j for j in await frontier.get_jobs_by_dag_id(dag_id)
                    }

                    level_to_executors = defaultdict(set)
                    job_states = {}
                    job_executors = {}

                    for node_id in sorted_node_ids:
                        job_info = job_info_map.get(node_id)
                        node_state = "NOT_FOUND"
                        executor = _get_executor_from_work_info(job_info)

                        if job_info:
                            if job_info.state:
                                node_state = job_info.state.value
                                if job_info.state.is_terminal():
                                    completed_nodes += 1
                            if job_info.job_level is not None:
                                level_to_executors[job_info.job_level].add(executor)

                        job_states[node_id] = node_state
                        job_executors[node_id] = executor

                    debug_file.write("    Level to Executor Mapping:\n")
                    for level, executors in sorted(level_to_executors.items()):
                        debug_file.write(
                            f"      Level {level}: {', '.join(sorted(list(executors)))}\n"
                        )
                    debug_file.write("\n")

                    debug_file.write("    Nodes (topological order):\n")

                    for node_id in sorted_node_ids:
                        node = node_map.get(node_id)
                        job_info = job_info_map.get(node_id)
                        node_name = f" ({node.query_str})" if node else ""
                        executor_info = job_executors.get(node_id, "UNKNOWN")
                        level_info = job_info.job_level if job_info else "N/A"
                        node_state_str = job_states.get(node_id, "NOT_FOUND")
                        debug_file.write(
                            f"      - {node_id} {node_state_str:<10} {level_info:<3} {executor_info:<24} {node_name} \n"
                        )

                    completion_percentage = (
                        (completed_nodes / total_nodes) * 100 if total_nodes > 0 else 0
                    )
                    debug_file.write(
                        f"    Completion: {completion_percentage:.2f}% ({completed_nodes}/{total_nodes} completed)\n\n"
                    )
                except Exception as e:
                    debug_file.write(f"    Error processing DAG {dag_id}: {e}\n\n")

        logger.debug(
            f"Candidates and planned jobs written to {debug_file_path} for analysis."
        )
    except Exception as debug_error:
        logger.error(
            f"Failed to write candidates and planned jobs to debug file: {debug_error}"
        )
