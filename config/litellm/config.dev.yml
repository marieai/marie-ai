# This is a configuration file for the Litellm library.
# https://docs.litellm.ai/docs/proxy/configs
#`openai/` prefix tells litellm it's openai compatible


model_list:
  - model_name: qwen_v2_5_vl
    litellm_params:
      model: openai/qwen/qwen_v2_5_vl
      api_key: EMPTY
      api_base: http://127.0.0.1:4000

  # Chat model for Mem0
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: ${OPENAI_API_KEY}

  # Embedding model for Mem0
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: ${OPENAI_API_KEY}

