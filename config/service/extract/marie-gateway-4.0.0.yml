!MarieGateway
uses: MarieGateway
py_modules:
  - marie.serve.runtimes.gateway.marie

# Currently the parameters have to be passed in as runtime arguments from command line
# This will be changed in the future
# marie gateway --uses /mnt/data/marie-ai/config/service/gateway.yml --protocols HTTP GRPC --ports 51000 52000

#protocols:
#  - "GRPC"
#  - "HTTP"
#
#ports:
#  - 54000
#  - 55000

#port_monitoring:
#  - 57706



# Postgres

# monitoring done by grafana/prometheus has been deprecated in favor of open-telemetry
#  monitoring: false
#  port_monitoring: 57843
tracing: False
traces_exporter_host: http://0.0.0.0
traces_exporter_port: 4317

metrics: False
metrics_exporter_host: http://0.0.0.0
metrics_exporter_port: 4317

# Shared configuration
shared_config:
  storage: &storage
    psql: &psql_conf_shared
      provider: postgresql
      hostname: ${{ ENV.POSTGRES_HOSTNAME }}
      port: 5432
      username: ${{ ENV.POSTGRES_USER }}
      password: ${{ ENV.POSTGRES_PASSWORD }}
      database: postgres
      default_table: shared_docs

  message: &message
    amazon_mq :  &amazon_mq_conf_shared
      provider: amazon-rabbitmq
      hostname: ${{ ENV.AWS_MQ_HOSTNAME }}
      port: 15672
      username: ${{ ENV.AWS_MQ_USERNAME }}
      password: ${{ ENV.AWS_MQ_PASSWORD }}
      tls: True
      virtualhost: /

    rabbitmq :  &rabbitmq_conf_shared
      provider: rabbitmq
      hostname: ${{ ENV.RABBIT_MQ_HOSTNAME }}
      port: ${{ ENV.RABBIT_MQ_PORT }}
      username: ${{ ENV.RABBIT_MQ_USERNAME }}
      password: ${{ ENV.RABBIT_MQ_PASSWORD }}
      tls: False
      virtualhost: /

# this will be passed in as runtime arguments in kwargs
with:

  discovery: true
#  discovery_host: mariectl-002:2379,mariectl-003:2379,mariectl-004:2379 # SINGLE HOST OR A LIST OF HOSTS
  discovery_host: 0.0.0.0 # SINGLE HOST OR A LIST OF HOSTS
  discovery_port: 2379
  discovery_watchdog_interval: 5 # DEPRECATED replace by discovery_heartbeat_sec
  discovery_service_name: gateway/marie
  discovery_namespace: marie
  discovery_lease_sec: 6
  discovery_heartbeat_sec: 1.5
  discovery_timeout_sec: 10
  discovery_retry_times : 5

#  discovery_ca_cert: "/path/to/ca.crt"
#  discovery_cert_key: "/path/to/client.key"
#  discovery_cert_cert: "/path/to/client.crt"
#  discovery_grpc_options: "grpc.keepalive_time_ms:30000,grpc.keepalive_timeout_ms:5000"

  discovery_ca_cert:
  discovery_cert_key:
  discovery_cert_cert:
  discovery_grpc_options:

  # Key Value Store
  kv_store_kwargs:
    <<: *psql_conf_shared
    default_table: kv_store_worker
    max_pool_size: 10
    max_connections: 25

    # Job Scheduler
  job_scheduler_kwargs:
    <<: *psql_conf_shared
    default_table: job_scheduler
    max_workers: 10
    max_pool_size: 10
    max_connections: 25
    queue_names: [extract,gen5_extract] # Queue names for the job scheduler to monitor

    # DAG Concurrency Management
    dag_manager:
      strategy: dynamic # fixed or dynamic
      min_concurrent_dags: 32      # Minimum number of concurrent DAGs (safety floor)
      max_concurrent_dags: 64     # Maximum number of concurrent DAGs (resource ceiling)
      cache_ttl_seconds: 10       # Cache TTL for capacity calculations

    # Planners have to be available in the python path.
    # When running in a container, the planners should be available in the container's python path.
    query_planners:
#      watch_wheels: True
#      wheel_directories:
#        - /mnt/data/marie-ai/config/wheels
      planners:
        - name: tid_100985
          py_module: grapnel_g5.query.tid_100985.query
        - name: tid_121880
          py_module: grapnel_g5.query.tid_121880.query
#        - name: corrflow_planner
#          py_module: corrflow.planner

  # Toast event tracking system
  # It can be backed by Message Queue or Database backed
  toast:
    native:
      enabled: True
      path: /tmp/marie/events.json
    rabbitmq:
      <<: *rabbitmq_conf_shared
      enabled : True
    psql:
      <<: *psql_conf_shared
      default_table: event_tracking
      enabled : True

  # Document Storage
  # The storage service is used to store the data that is being processed
  # Storage can be backed by S3 compatible

  storage:
    # S3 configuration. Will be used only if value of backend is "s3"
    s3:
      enabled: True
      metadata_only: False # If True, only metadata will be stored in the storage backend
      # api endpoint to connect to. use AWS S3 or any S3 compatible object storage endpoint.
      endpoint_url: ${{ ENV.S3_ENDPOINT_URL }}
      # optional.
      # access key id when using static credentials.
      access_key_id: ${{ ENV.S3_ACCESS_KEY_ID }}
      # optional.
      # secret key when using static credentials.
      secret_access_key: ${{ ENV.S3_SECRET_ACCESS_KEY }}
      # Bucket name in s3
      bucket_name: ${{ ENV.S3_BUCKET_NAME }}
      # optional.
      # Example: "region: us-east-2"
      region: ${{ ENV.S3_REGION }}
      # optional.
      # enable if endpoint is http
      insecure: True
      # optional.
      # enable if you want to use path style requests
      addressing_style: path

    # postgresql configuration. Will be used only if value of backend is "psql"
    psql:
      <<: *psql_conf_shared
      default_table: store_metadata
      enabled : False

  # Authentication and Authorization configuration
  auth:
    keys:
      - name : service-A
        api_key : mas_0aPJ9Q9nUO1Ac1vJTfffXEXs9FyGLf9BzfYgZ_RaHm707wmbfHJNPQ
        enabled : True
        roles : [admin, user]

      - name : gen5
        api_key : mau_B9-RGDZ6LUNQ7s1FlzeJ2m9Qo5SSAcWXDkgRLrsjVwdtxQ0FH4dRww
        enabled : True
        roles : [admin, user]

      - name : service-B
        api_key : mau_t6qDi1BcL1NkLI8I6iM8z1va0nZP01UQ6LWecpbDz6mbxWgIIIZPfQ
        enabled : True
        roles : [admin, user]
