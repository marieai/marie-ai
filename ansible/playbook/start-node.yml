---

- name: Deploy to node
  hosts: ml_cluster
  gather_facts: true
  vars:
    stack_name: "dev"
    
    image_tag: 3.0.30-cuda
    config_tag: marie-3.0.30.yml
    
    image_tagLAST: 3.0.26-cuda
    config_tagLAST: marie-3.0.21.yml
    
    server_port: 8080
  tasks:
#    - name: Create network
#      community.docker.docker_network:
#        name: "marie-{{ stack_name }}"
#        state: present
#        driver: bridge
    # https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_module.html
    - name: Run the inference-server
      community.docker.docker_container:
        name: "marieai-{{ stack_name }}-server"
        image: "marieai/marie:{{ image_tag }}"
        state: started
        recreate: "{{ (stack_name == 'dev') | bool }}"
#        auto_remove: "{{ (stack_name == 'dev') | bool }}"
        pull: true
        tty: true
        restart_policy: "always" # always | on-failure | unless-stopped
        network_mode: host #"marie-{{ stack_name }}"
        command: server --start --uses /etc/marie/config/service/{{ config_tag }}
        device_requests:
          - # Add nVidia GPUs to this container
            driver: nvidia
            count: -1  # this means we want all
            capabilities:
              - gpu
              - compute
              - utility
              # See https://github.com/NVIDIA/nvidia-container-runtime#supported-driver-capabilities
              # for a list of capabilities supported by the nvidia driver

        log_driver: local
        log_options:
          max-size: 100m
          max-file: 10
        env:
          MARIE_CACHE_SKIP_LOAD: "true" # causes issues with docker
          MARIE_DEFAULT_MOUNT: "/etc/marie"
          MARIE_LOG_CONFIG: docker
          MARIE_DEPLOYMENT_NAME: marie
          COLUMNS: "180"
          JINA_MP_START_METHOD: "fork"
          JINA_LOG_LEVEL:
            "{{ lookup('ansible.builtin.env', 'JINA_LOG_LEVEL') | default('DEBUG', true) }}"
#        ports:
#          - "{{ server_port }}:8080"

#        MARIE_DEBUG=1;MARIE_DEBUG_PORT=5678;MARIE_DEBUG_WAIT_FOR_CLIENT=1;MARIE_DEBUG_HOST=0.0.0.0
#          MARIE_DEBUG: "1"
#          MARIE_DEBUG_PORT: "5678"
#          MARIE_DEBUG_WAIT_FOR_CLIENT: "1"
#          MARIE_DEBUG_HOST: "0.0.0.0"
        volumes:
          - "/mnt/data/marie-ai/config:/etc/marie/config:ro"
          - "/mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw"
          - "/mnt/data/marie-ai/config/service/im-policy.xml:/etc/ImageMagick-6/policy.xml:ro"
          - "/mnt/data/marie-ai/model_zoo/cache/huggingface/hub:/root/.cache/huggingface/hub:rw"

# Docker debug command
# docker container ls -aq | xargs --no-run-if-empty docker stop && docker rm $(docker ps --filter status=exited -q)
# docker run --gpus all --name=marieai  --network=host -e JINA_LOG_LEVEL=debug -e MARIE_DEFAULT_MOUNT='/etc/marie' -v /mnt/data/marie-ai/config:/etc/marie/config:ro -v /mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw marieai/marie:3.0.18-cuda server --start --uses /etc/marie/config/service/marie.yml


# Run interactive
# /opt/venv/lib/python3.10/site-packages/marie_server#
# docker run --rm  -it --entrypoint /bin/bash --gpus all --name=marieai  --network=host -e JINA_LOG_LEVEL=debug -e MARIE_DEFAULT_MOUNT='/etc/marie' -v /mnt/data/marie-ai/config:/etc/marie/config:ro -v /mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw marieai/marie:3.0.25-cuda
# pip install debugpy
# /opt/venv/lib/python3.10/site-packages/marie_server#
# MARIE_DEBUG=1;MARIE_DEBUG_PORT=5678;MARIE_DEBUG_WAIT_FOR_CLIENT=1;MARIE_DEBUG_HOST=0.0.0.0 marie server --start --uses /etc/marie/config/service/marie-3.0.2x-corr.yml
