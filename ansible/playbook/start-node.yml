---

- name: Deploy to node
  hosts: ml.cluster
  gather_facts: true
  vars:
    stack_name: "dev"
    image_tag_prev: 3.0.19-cuda
    image_tag: 3.0.20-cuda
    server_port: 8080
  tasks:
#    - name: Create network
#      community.docker.docker_network:
#        name: "marie-{{ stack_name }}"
#        state: present
#        driver: bridge
    # https://docs.ansible.com/ansible/latest/collections/community/docker/docker_container_module.html
    - name: Run the inference-server
      community.docker.docker_container:
        name: "marieai-{{ stack_name }}-server"
        image: "marieai/marie:{{ image_tag }}"
        state: started
        recreate: "{{ (stack_name == 'dev') | bool }}"
#        auto_remove: "{{ (stack_name == 'dev') | bool }}"
        pull: true
        tty: true
        restart_policy: "always" # always | on-failure | unless-stopped
        network_mode: host #"marie-{{ stack_name }}"
        command: server --start --uses /etc/marie/config/service/marie.yml
        device_requests:
          - # Add nVidia GPUs to this container
            driver: nvidia
            count: -1  # this means we want all
            capabilities:
              - gpu
              - compute
              - utility
              # See https://github.com/NVIDIA/nvidia-container-runtime#supported-driver-capabilities
              # for a list of capabilities supported by the nvidia driver
        
        log_driver: local
        log_options:
          max-size: 100m
          max-file: 10
        env:
          MARIE_DEFAULT_MOUNT: "/etc/marie"
          MARIE_LOG_CONFIG: docker
          MARIE_DEPLOYMENT_NAME: marie
          COLUMNS: "180"
          JINA_MP_START_METHOD: "fork"
          JINA_LOG_LEVEL:
            "{{ lookup('ansible.builtin.env', 'JINA_LOG_LEVEL') | default('DEBUG', true) }}"
#        ports:
#          - "{{ server_port }}:8080"
        volumes:
          - "/mnt/data/marie-ai/config:/etc/marie/config:ro"
          - "/mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw"

# Docker debug command
# docker container ls -aq | xargs --no-run-if-empty docker stop && docker rm $(docker ps --filter status=exited -q)
# docker run --gpus all --name=marieai  --network=host -e JINA_LOG_LEVEL=debug -e MARIE_DEFAULT_MOUNT='/etc/marie' -v /mnt/data/marie-ai/config:/etc/marie/config:ro -v /mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw marieai/marie:3.0.18-cuda server --start --uses /etc/marie/config/service/marie.yml