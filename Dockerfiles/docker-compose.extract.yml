# ############### Marie-AI Extract Executors ###############

# GPU-enabled inference servers for document extraction

services:
  marie-extract-executor:
    image: marieai/marie:${EXTRACT_IMAGE_TAG:-4.0.0-cuda}
    restart: unless-stopped
    container_name: 'marieai-${EXTRACT_STACK_NAME:-dev}-server'
    init: true
    tty: true
    network_mode: host
#    networks:
#      - marie_default
    command: >
      server --start 
      --uses /etc/marie/config/service/extract/${EXTRACT_CONFIG_TAG:-marie-extract-4.0.0.yml}

    environment:
      - MARIE_CACHE_SKIP_LOAD=true
      - MARIE_DEFAULT_MOUNT=/etc/marie
      - MARIE_LOG_CONFIG=docker
      - MARIE_DEPLOYMENT_NAME=marie
      - COLUMNS=180
      - JINA_MP_START_METHOD=spawn
      - JINA_LOG_LEVEL=${EXTRACT_LOG_LEVEL:-DEBUG}

    volumes:
      - /mnt/data/marie-ai/config:/etc/marie/config:ro
      - /mnt/data/marie-ai/model_zoo:/etc/marie/model_zoo:rw
      - /mnt/data/marie-ai/model_zoo/cache/huggingface/hub:/root/.cache/huggingface/hub:rw
      - /mnt/data/marie-ai/config/service/im-policy.xml:/etc/ImageMagick-6/policy.xml:ro

    # Fixed GPU configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
                - compute
                - utility
        limits:
          memory: 32G

    logging:
      driver: local
      options:
        max-size: "100m"
        max-file: "10"

#    healthcheck:
#      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/status', timeout=5)"]
#      interval: 60s
#      timeout: 30s
#      retries: 3
#      start_period: 300s

    labels:
      - "marie.service=extract-executor"
      - "marie.version=${EXTRACT_IMAGE_TAG:-4.0.0-cuda}"

networks:
  marie_default:
    external: true